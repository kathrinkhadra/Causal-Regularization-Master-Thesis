import numpy as np
import matplotlib.pyplot as plt

x_axis=[10,20,30,40,50,60,70,80,90,100,110,120,130,140,150,160,170,180,190,200,210,220,230,240,250,260,270,280,290,300,310,320,330,340,350,360,370,380,390,400,410,420,430,440,450]
ACE_loss=[0.13203,0.0518443,0.0373443,0.0287096,0.0229515,0.0180216,0.014642,0.0121259,0.0104428,0.00925074,0.00829975,0.007379,0.00654603,0.00585197,0.00526291,0.00471692,0.00428678,0.00402006,0.00380802,0.00362949,0.00348574,0.00337224,0.00327594,0.00318628,0.00309656,0.00300386,0.002918,0.00283153,0.00273186,0.00263788,0.0025192,0.00240318,0.002284,0.00216441,0.00203645,0.00190925,0.00178066,0.00166254,0.00155779,0.00145655,0.00133126,0.00122383,0.00114583,0.00108763,0.00104727]
ACE_test_loss=0.0116

loss=[0.102127,0.060423,0.0397786,0.032694,0.0256563,0.0196332,0.0150592,0.0124586,0.0106226,0.00905151,0.00779522,0.006649,0.00562255,0.00472965,0.00402863,0.00348846,0.00309285,0.00279684,0.00252005,0.00225035,0.00200137,0.00179351,0.00160537,0.00143398,0.00128152,0.00114327,0.00102102,0.000916448,0.000824641,0.000742866,0.000675294,0.000612492,0.000547459,0.0004983,0.00046165,0.000430733,0.000406023,0.000386077,0.00037011,0.0003565,0.00034554,0.0003355,0.000326441,0.000317556,0.000310321]

test_loss=0.0105

#print(np.array(ACE_loss).shape)
#print(np.array(loss).shape)
#print(np.array(x_axis).shape)
index=0

#plt.plot(np.array(x_axis)[index:],np.array(ACE_loss)[index:], label="training loss with ACE")
#plt.plot(np.array(x_axis)[index:],np.array(loss)[index:], label="training loss without ACE")
#plt.plot(450,test_loss, marker='o', label="test loss without ACE")
#plt.plot(450,ACE_test_loss, marker='o', label="test loss with ACE")
#plt.xlabel('Actual value of training set')
#plt.ylabel('Prediction')
#plt.legend(loc='upper right')
#plt.savefig("ACE_training_test_comparison.png")
#plt.close()

means=[[ 1.14590369e-03,  4.29754896e-04, -2.32663406e-04, -2.32663406e-04,
       -2.32663406e-04, -1.36855090e-03, -1.88624535e-03,  1.03072269e-02,
       -2.47659940e-03, -5.22876706e-04,  2.25278786e-03,  3.38107963e-03,
       -2.53913393e-03,  3.14954208e-02, -2.32663406e-04, -1.93480654e-03,
       -2.32663406e-04, -1.43431104e-03,  8.38036134e-03, -2.32663406e-04,
       -3.73561984e-04, -6.95600057e-04, -2.04201856e-03, -2.32663406e-04,
       -1.58270056e-03, -2.32663406e-04,  2.03038294e-03, -1.68340371e-03,
        4.00512164e-03,  1.23296805e-03,  1.90440554e-04, -9.84634632e-05,
       -1.76749350e-03,  7.34533724e-04,  3.94347058e-04, -6.99097842e-04,
        9.16706218e-04,  2.61570872e-03,  2.39219120e-03, -2.32663406e-04,
       -1.43152745e-02, -2.32663406e-04, -4.09331801e-03, -4.10258993e-04,
       -2.32663406e-04,  6.72916703e-03,  3.89902805e-04, -2.32663406e-04,
       -2.32663406e-04, -2.32663406e-04],[-3.74891650e-04, -3.33857217e-04, -3.33857217e-04,  4.30547182e-04,
       -2.22360867e-04, -1.43148499e-03,  4.58796804e-03,  2.34220455e-03,
       -1.94434763e-04, -3.33857217e-04,  3.59308735e-04, -1.41523714e-03,
        8.07257075e-04,  1.14863095e-03,  8.73607909e-04,  8.86657084e-06,
       -3.33857217e-04,  3.93839032e-04, -1.45892388e-03,  6.28409893e-05,
       -1.06247626e-03, -9.91375993e-04,  9.44285785e-04, -3.33857217e-04,
       -3.33857217e-04, -4.48854432e-04, -6.77630116e-04, -3.33857217e-04,
       -3.33857217e-04, -2.93592601e-04,  2.46651072e-03, -2.83980921e-04,
       -3.33857217e-04, -6.63543287e-04, -3.33857217e-04,  1.45890366e-03,
       -1.65781513e-04, -3.33857217e-04, -6.38552109e-06, -3.33857217e-04,
        3.31085416e-05,  5.61954219e-04, -5.55198689e-04, -5.73562166e-04,
       -3.33857217e-04, -3.33857217e-04, -4.34151912e-04, -2.21026111e-04,
       -6.54216095e-05, -2.75547033e-03, -2.94452499e-03,  1.98424488e-04,
        1.25139955e-03, -3.33857217e-04, -3.33857217e-04, -3.33857217e-04,
       -3.33857217e-04, -3.33857217e-04,  7.57312260e-05, -6.45706460e-04,
       -3.33857217e-04,  1.09883711e-03, -3.33857217e-04, -2.09994222e-03,
       -3.33857217e-04, -3.25895877e-03, -3.33857217e-04,  2.33446229e-05,
       -5.10998131e-04, -1.42566011e-03,  1.68859468e-03, -5.21792460e-04,
        1.31935282e-03, -3.33857217e-04, -1.33853438e-03, -3.82205411e-04,
        2.33885861e-05, -3.99671539e-04, -2.42724007e-04, -3.33857217e-04,
       -5.22739988e-04, -3.81369494e-04, -3.10436790e-07, -3.33857217e-04,
       -3.33857217e-04, -3.33857217e-04, -1.37944119e-04, -4.53704120e-03,
       -4.22454772e-04,  6.48963679e-03, -3.33857217e-04, -1.12127705e-03,
       -5.28186050e-04, -3.33857217e-04, -3.33857217e-04,  5.47251058e-04,
       -3.33857217e-04, -3.33857217e-04, -3.33857217e-04, -4.07030320e-03],[ 3.17397690e-04,  1.68311632e-04,  1.77117811e-04,  7.62851439e-04,
        4.52191209e-04,  7.74753784e-05, -6.25662534e-04, -1.77880172e-04,
       -1.77880172e-04, -1.87210589e-03, -2.24188570e-03, -1.77880172e-04,
       -2.62042835e-04, -1.77880172e-04, -2.95658246e-04, -2.47484665e-04,
        1.31183787e-04, -4.15613831e-04, -1.77880172e-04, -2.60149031e-04,
       -1.42659595e-04,  1.83498133e-03, -1.98073686e-04,  1.98246646e-04,
       -1.77880172e-04, -1.77880172e-04,  2.59859694e-05, -1.52196539e-03,
        7.89369082e-04, -6.67268208e-04,  2.06687062e-03, -1.77880172e-04,
       -1.77880172e-04, -1.35755701e-03, -1.77880172e-04, -3.95623031e-03,
       -8.48705213e-05,  4.74557474e-04, -3.84887560e-04, -1.77880172e-04,
       -1.77880172e-04, -4.21833947e-04, -4.32890596e-06, -1.77880172e-04,
        6.69868826e-04,  1.96994860e-03,  6.22903084e-04, -1.77880172e-04,
       -1.77880172e-04, -1.77880172e-04]]

#for mean in means:
plt.plot(0,7.275121119625292e-06,marker='o')

plt.show()

#f = open("results.txt", 'a')

#f.write('x_axis='+str(x_axis)+'\n\n')
#f.write('ACE_loss='+str(ACE_loss)+'\n\n')

#f = open("results.txt", 'a')
#f.write('loss='+str(loss)+'\n\n')

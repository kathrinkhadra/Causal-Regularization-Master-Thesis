[0.         0.         0.13759812 0.14893086 0.         0.14886751
0.         0.         0.17882849 0.21423085 0.         0.
0.         0.         0.         0.18371565 0.         0.
0.         0.         0.         0.19940344 0.         0.
0.         0.         0.21064653 0.         0.07384746 0.06450659
0.         0.         0.18710519 0.         0.0969613  0.
0.         0.11849175 0.0953715  0.         0.         0.11519665
0.         0.         0.         0.2245973  0.         0.17914888
0.         0.        ]

#first Loop 0

#second Loop 1


nn generating input
Sequential(
  (0): Linear(in_features=13, out_features=50, bias=True)
  (1): ReLU()
  (2): Linear(in_features=50, out_features=100, bias=True)
  (3): ReLU()
)
sliced NN
Sequential(
  (4): Linear(in_features=100, out_features=50, bias=True)
  (5): ReLU()
  (6): Linear(in_features=50, out_features=1, bias=True)
)


lower_order_grads
(tensor([-0.1182,  0.0380, -0.0824,  0.0886,  0.1005,  0.1235,  0.0322,  0.1682,
        -0.0364, -0.1097, -0.0700,  0.1298, -0.1313,  0.0937, -0.0975, -0.1488,
        -0.1006, -0.0799,  0.0875,  0.2585,  0.0489,  0.0326,  0.1407, -0.0980,
        -0.0997,  0.0378,  0.0715,  0.0766,  0.1501, -0.1164,  0.1198, -0.2011,
        -0.1334, -0.0125,  0.1181,  0.1030, -0.1234, -0.0164, -0.0267,  0.1194,
         0.0648, -0.0747, -0.1000, -0.0930,  0.0348, -0.1079,  0.0767, -0.0593,
         0.1628,  0.0192], grad_fn=<SqueezeBackward1>),)
         
input_tensor
tensor([0.0000, 0.2845, 0.0214, 0.2287, 0.2985, 0.2395, 0.2394, 0.1395, 0.0000,
        0.0000, 0.0000, 0.2782, 0.0000, 0.1732, 0.2289, 0.1788, 0.2144, 0.0000,
        0.0668, 0.0369, 0.0000, 0.0000, 0.5095, 0.1657, 0.0000, 0.1771, 0.1947,
        0.0000, 0.2507, 0.0000, 0.0000, 0.0038, 0.0000, 0.0000, 0.0000, 0.1523,
        0.0000, 0.0000, 0.0153, 0.0000, 0.2065, 0.0000, 0.1898, 0.2522, 0.1701,
        0.0000, 0.2133, 0.0207, 0.1862, 0.0000], requires_grad=True)
